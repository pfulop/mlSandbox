{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset \n",
    "import glob\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 36\n",
    "height = 64\n",
    "emb_w = width // 4\n",
    "emb_h = height // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/run/media/backman/yay/uiD'\n",
    "MODEL2_PATH = '/run/media/backman/yay/uiG'\n",
    "\n",
    "def save_model():\n",
    "    torch.save(netD.state_dict(), MODEL_PATH)\n",
    "    torch.save(netG.state_dict(), MODEL2_PATH)\n",
    "    \n",
    "def load_model():\n",
    "    netD.load_state_dict(torch.load(MODEL_PATH))\n",
    "    netG.load_state_dict(torch.load(MODEL2_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images():\n",
    "    root_dir = '/run/media/backman/yay/unique_uis/combined/'\n",
    "    new_dir = '/run/media/backman/yay/unique_uis/resized/'\n",
    "    files = glob.glob(root_dir + '*.jpg')\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            im = Image.open(file)\n",
    "            im.thumbnail((width,height), Image.ANTIALIAS)\n",
    "            assert im.size == (width,height)\n",
    "            im.save(new_dir+os.path.basename(file),\"JPEG\")\n",
    "        except IOError:\n",
    "            pass\n",
    "        except AssertionError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleUIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = glob.glob(root_dir + '*.jpg')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.files[idx])\n",
    "        image = io.imread(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, tuple)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w), mode='constant')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GoogleUIDataset('/run/media/backman/yay/unique_uis/resized/',\n",
    "                                                   transform=transforms.Compose([\n",
    "#                                                     Rescale((36, 64)),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                                   ]))\n",
    "guid = torch.utils.data.DataLoader(g,\n",
    "                                   bs, True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 128, emb_h, emb_w)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "\n",
    "    def conv_sub_block(self, in_c, out_c, sub = False):\n",
    "        conv_sub_arr = []\n",
    "        conv_sub_arr.append(nn.Conv2d(in_c, in_c, 3, padding=1))\n",
    "        conv_sub_arr.append(nn.ELU())\n",
    "        conv_sub_arr.append(nn.Conv2d(in_c, out_c, 3, padding=1))\n",
    "        conv_sub_arr.append(nn.ELU())\n",
    "        if sub:\n",
    "            conv_sub_arr.append(nn.Conv2d(out_c, out_c, 3, stride = 2, padding=1))\n",
    "            conv_sub_arr.append(nn.ELU())\n",
    "        return conv_sub_arr\n",
    "    \n",
    "    def deconv_up_block(self, in_c, out_c = None, up = False):\n",
    "        if out_c is None:\n",
    "            out_c = in_c\n",
    "        deconv_sub_arr = []\n",
    "        deconv_sub_arr.append(nn.Conv2d(in_c, in_c, 3, padding=1))\n",
    "        deconv_sub_arr.append(nn.ELU())\n",
    "        deconv_sub_arr.append(nn.Conv2d(in_c, out_c, 3, padding=1))\n",
    "        deconv_sub_arr.append(nn.ELU())\n",
    "        if up:\n",
    "            deconv_sub_arr.append(nn.Upsample(scale_factor = 2, mode='nearest'))\n",
    "            deconv_sub_arr.append(nn.ELU())\n",
    "        return deconv_sub_arr\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "\n",
    "        n = 128\n",
    "        h = 64 #noise vector\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3, n, 3, padding=1)) #36x64x128\n",
    "        layers += self.conv_sub_block(n, n*2, True) #18x32x256\n",
    "        layers += self.conv_sub_block(n*2, n*3, True)#9x16x384\n",
    "        layers += self.conv_sub_block(n*3, n*3)#9x16x384\n",
    "        layers.append(Flatten())#15360\n",
    "        layers.append(nn.Linear(3*emb_h*emb_w*n, h)) #64\n",
    " \n",
    "        layers.append(nn.Linear(h,emb_h*emb_w*n)) #5120\n",
    "        layers.append(Reshape()) #16x9x128\n",
    "        layers += self.deconv_up_block(n, 2*n, up = True)#9x16x256\n",
    "        layers += self.deconv_up_block(2*n, 2*n, True)#18x32x256\n",
    "        layers += self.deconv_up_block(2*n, n)#36x64x128\n",
    "        layers.append(nn.Conv2d(n, 3, 3, padding=1))#36x64x3\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    \n",
    "    def deconv_up_block(self, in_c, out_c = None, up = False):\n",
    "        if out_c is None:\n",
    "            out_c = in_c\n",
    "        deconv_sub_arr = []\n",
    "        deconv_sub_arr.append(nn.Conv2d(in_c, in_c, 3, padding=1))\n",
    "        deconv_sub_arr.append(nn.ELU())\n",
    "        deconv_sub_arr.append(nn.Conv2d(in_c, out_c, 3, padding=1))\n",
    "        deconv_sub_arr.append(nn.ELU())\n",
    "        if up:\n",
    "            deconv_sub_arr.append(nn.Upsample(scale_factor = 2, mode='nearest'))\n",
    "            deconv_sub_arr.append(nn.ELU())\n",
    "        return deconv_sub_arr\n",
    "\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        n = 128\n",
    "        h = 64 #noise vector\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(h,emb_h*emb_w*n)) \n",
    "        layers.append(Reshape())\n",
    "        layers += self.deconv_up_block(n, 2*n, up = True)\n",
    "        layers += self.deconv_up_block(2*n, 2*n, True)\n",
    "        layers += self.deconv_up_block(2*n, n)\n",
    "        layers.append(nn.Conv2d(n, 3, 3, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = dtype(bs, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D (\n",
       "  (model): Sequential (\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ELU (alpha=1.0)\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ELU (alpha=1.0)\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (6): ELU (alpha=1.0)\n",
       "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ELU (alpha=1.0)\n",
       "    (9): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ELU (alpha=1.0)\n",
       "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): ELU (alpha=1.0)\n",
       "    (13): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ELU (alpha=1.0)\n",
       "    (15): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ELU (alpha=1.0)\n",
       "    (17): Flatten (\n",
       "    )\n",
       "    (18): Linear (55296 -> 64)\n",
       "    (19): Linear (64 -> 18432)\n",
       "    (20): Reshape (\n",
       "    )\n",
       "    (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ELU (alpha=1.0)\n",
       "    (23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ELU (alpha=1.0)\n",
       "    (25): Upsample(scale_factor=2, mode=nearest)\n",
       "    (26): ELU (alpha=1.0)\n",
       "    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): ELU (alpha=1.0)\n",
       "    (29): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (30): ELU (alpha=1.0)\n",
       "    (31): Upsample(scale_factor=2, mode=nearest)\n",
       "    (32): ELU (alpha=1.0)\n",
       "    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): ELU (alpha=1.0)\n",
       "    (35): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (36): ELU (alpha=1.0)\n",
       "    (37): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    netG = netG.cuda()\n",
    "    netD = netD.cuda()\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_image(batch):\n",
    "    var = batch\n",
    "    if use_cuda:\n",
    "        var = var.cuda()\n",
    "    return Variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_image():\n",
    "    noise.data.normal_(0, 1)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs = 1, k_t = 0, lambda_k = 0.001, gamma = 0.5):\n",
    "    n_batches = len(guid)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        for iteration in range(n_batches):\n",
    "            data_iter = iter(guid)\n",
    "            max_D_train = 5 if n_batches - iteration >= 5 else 1 \n",
    "            for _ in range(max_D_train):\n",
    "                #real image\n",
    "                real = get_real_image(next(data_iter))\n",
    "                netD.zero_grad()\n",
    "                loss_real = torch.mean(torch.abs(netD(real) - real))\n",
    "                \n",
    "                #fake image\n",
    "                fake = netG(get_fake_image())\n",
    "                loss_fake = torch.mean(torch.abs(netD(fake) - fake))\n",
    "                loss_discriminator = loss_real - k_t * loss_fake\n",
    "                loss_discriminator.backward()\n",
    "                optimizerD.step()\n",
    "                \n",
    "            netG.zero_grad()\n",
    "            #discriminator should not be trainable here\n",
    "            fake = get_fake_image()\n",
    "            loss_generator = torch.mean(torch.abs(netG(fake) - netD(netG(fake))))\n",
    "            loss_generator.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "            update = gamma * loss_real - loss_generator\n",
    "            update = update.data[0]\n",
    "            \n",
    "            k_t += lambda_k * update \n",
    "            k_t = max(min(1, k_t), 0)\n",
    "            \n",
    "            if iteration % 500 == 0:\n",
    "                print(f'step: {iteration} / {n_batches} (epoch: {epoch}); loss_generator: {loss_generator.data[0]}; loss_discriminator:  {loss_discriminator.data[0]}')\n",
    "                \n",
    "    return k_t\n",
    "                \n",
    "            \n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 0); loss_generator: 1.7083899974822998; loss_discriminator:  3.819852828979492\n",
      "step: 500 / 18026 (epoch: 0); loss_generator: 0.20671911537647247; loss_discriminator:  0.3347068727016449\n",
      "step: 1000 / 18026 (epoch: 0); loss_generator: 1346888.875; loss_discriminator:  9.81289291381836\n",
      "step: 1500 / 18026 (epoch: 0); loss_generator: 198946.734375; loss_discriminator:  0.7392663359642029\n",
      "step: 2000 / 18026 (epoch: 0); loss_generator: 678866.4375; loss_discriminator:  0.6034988164901733\n",
      "step: 2500 / 18026 (epoch: 0); loss_generator: 302023.15625; loss_discriminator:  1.5192229747772217\n",
      "step: 3000 / 18026 (epoch: 0); loss_generator: 18736.03125; loss_discriminator:  0.9140139818191528\n",
      "step: 3500 / 18026 (epoch: 0); loss_generator: 85576.4609375; loss_discriminator:  0.7061715126037598\n",
      "step: 4000 / 18026 (epoch: 0); loss_generator: 38523.7421875; loss_discriminator:  0.6348733305931091\n",
      "step: 4500 / 18026 (epoch: 0); loss_generator: 19091.802734375; loss_discriminator:  0.6800902485847473\n",
      "step: 5000 / 18026 (epoch: 0); loss_generator: 11331049619456.0; loss_discriminator:  54385656.0\n",
      "step: 5500 / 18026 (epoch: 0); loss_generator: 1500037729222656.0; loss_discriminator:  125621272576.0\n",
      "step: 6000 / 18026 (epoch: 0); loss_generator: 217685484896256.0; loss_discriminator:  5237631352832.0\n",
      "step: 6500 / 18026 (epoch: 0); loss_generator: 122975363072.0; loss_discriminator:  6604813824.0\n",
      "step: 7000 / 18026 (epoch: 0); loss_generator: 56199233536.0; loss_discriminator:  3790640128.0\n",
      "step: 7500 / 18026 (epoch: 0); loss_generator: 29019660288.0; loss_discriminator:  2377633024.0\n",
      "step: 8000 / 18026 (epoch: 0); loss_generator: 13813861376.0; loss_discriminator:  1133116416.0\n",
      "step: 8500 / 18026 (epoch: 0); loss_generator: 204.70889282226562; loss_discriminator:  0.5324808359146118\n",
      "step: 9000 / 18026 (epoch: 0); loss_generator: 257.8035583496094; loss_discriminator:  0.590971827507019\n",
      "step: 9500 / 18026 (epoch: 0); loss_generator: 194.1862030029297; loss_discriminator:  0.5505359172821045\n",
      "step: 10000 / 18026 (epoch: 0); loss_generator: 153.2140350341797; loss_discriminator:  0.7580032348632812\n",
      "step: 10500 / 18026 (epoch: 0); loss_generator: 211.23512268066406; loss_discriminator:  0.6415801048278809\n",
      "step: 11000 / 18026 (epoch: 0); loss_generator: 131.02784729003906; loss_discriminator:  0.732381284236908\n",
      "step: 11500 / 18026 (epoch: 0); loss_generator: 150.11451721191406; loss_discriminator:  0.6320366263389587\n",
      "step: 12000 / 18026 (epoch: 0); loss_generator: 150.05455017089844; loss_discriminator:  0.5582888722419739\n",
      "step: 12500 / 18026 (epoch: 0); loss_generator: 207.56626892089844; loss_discriminator:  0.7808361053466797\n",
      "step: 13000 / 18026 (epoch: 0); loss_generator: 137.45187377929688; loss_discriminator:  0.7638944983482361\n",
      "step: 13500 / 18026 (epoch: 0); loss_generator: 141.07516479492188; loss_discriminator:  0.7367968559265137\n",
      "step: 14000 / 18026 (epoch: 0); loss_generator: 103.22957611083984; loss_discriminator:  0.7166814208030701\n",
      "step: 14500 / 18026 (epoch: 0); loss_generator: 233.7910919189453; loss_discriminator:  0.6785351634025574\n",
      "step: 15000 / 18026 (epoch: 0); loss_generator: 239.90013122558594; loss_discriminator:  0.670600175857544\n",
      "step: 15500 / 18026 (epoch: 0); loss_generator: 268.1186218261719; loss_discriminator:  0.8585753440856934\n",
      "step: 16000 / 18026 (epoch: 0); loss_generator: 78.20001983642578; loss_discriminator:  0.7509315013885498\n",
      "step: 16500 / 18026 (epoch: 0); loss_generator: 264.916259765625; loss_discriminator:  0.6042892336845398\n",
      "step: 17000 / 18026 (epoch: 0); loss_generator: 164.98983764648438; loss_discriminator:  0.6185051798820496\n",
      "step: 17500 / 18026 (epoch: 0); loss_generator: 228.66685485839844; loss_discriminator:  0.7228484749794006\n",
      "step: 18000 / 18026 (epoch: 0); loss_generator: 253.12599182128906; loss_discriminator:  0.6251159310340881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [4:42:05<00:00, 16925.07s/it]\n"
     ]
    }
   ],
   "source": [
    "k_t = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1804  0.2902  0.2667  ...   0.3490  0.2706  0.1529\n",
      "  0.5373  0.7294  0.7373  ...   0.7451  0.6784  0.5608\n",
      "  0.6078  0.8588  0.8157  ...   0.8314  0.7647  0.6549\n",
      "           ...             ⋱             ...          \n",
      "  0.5412  0.8980  0.7922  ...   0.8000  0.7333  0.6196\n",
      "  0.4118  0.7255  0.6902  ...   0.6667  0.6118  0.5098\n",
      "  0.0510  0.0784  0.0588  ...   0.1255  0.0980  0.0235\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.1333  0.2235  0.2627  ...   0.2667  0.2353  0.1412\n",
      "  0.4588  0.6275  0.6941  ...   0.6510  0.6235  0.5294\n",
      "  0.5176  0.7373  0.7490  ...   0.7294  0.6980  0.6157\n",
      "           ...             ⋱             ...          \n",
      "  0.4980  0.7216  0.6510  ...   0.6902  0.6549  0.5686\n",
      "  0.4078  0.6000  0.6078  ...   0.5725  0.5490  0.4824\n",
      "  0.1020  0.0314  0.0667  ...   0.0392  0.0471  0.0039\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.2118  0.2941  0.2824  ...   0.3412  0.3098  0.2157\n",
      "  0.5647  0.7333  0.7608  ...   0.7137  0.6745  0.5804\n",
      "  0.4941  0.7255  0.7176  ...   0.6627  0.6196  0.5098\n",
      "           ...             ⋱             ...          \n",
      "  0.5608  0.7020  0.6902  ...   0.7451  0.6980  0.6078\n",
      "  0.6431  0.6039  0.5882  ...   0.6235  0.5922  0.5137\n",
      "  0.4784  0.0471  0.0000  ...   0.0863  0.0863  0.0314\n",
      "[torch.cuda.FloatTensor of size 1x3x64x36 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.6302 -0.7386  1.2481  0.5164 -1.3041 -0.2981  0.0114  0.6517 -0.5051  0.0160\n",
      " 0.6375 -1.5302  0.1598 -0.7488  0.1082 -0.3069 -1.1924 -0.9290  0.5236  0.7391\n",
      "-0.6739  0.7840  0.3240 -0.7538  0.6493 -0.4672 -0.7324 -1.1224 -1.4978 -0.2297\n",
      "-1.3289  0.3778  0.1970 -1.4683  0.6362  1.9921  0.9884 -0.4425  0.9064 -1.7319\n",
      "\n",
      "Columns 10 to 19 \n",
      " 0.0081  0.6219 -1.4425  1.5142  0.2987  0.8529  0.7515  0.2645 -1.8185  0.9106\n",
      " 0.5152  0.7952  0.0113  2.2761 -0.4509  1.2100 -1.2181  0.1203  2.3542 -0.1264\n",
      " 1.7046  1.3427  0.9234 -0.9227  1.6678  0.1804 -1.4999 -1.2514  0.7686 -0.1204\n",
      "-0.0540 -1.0072  1.6322 -0.2580 -2.5783  0.2639 -1.8285  0.2245 -0.6481 -0.6133\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.0993 -0.5156  0.7299 -0.6795 -0.9818  1.8068 -0.4952 -0.9440  0.0135  0.2142\n",
      " 0.3915  1.0841 -1.8010 -1.4935 -1.6272 -0.5115 -0.1436  0.8262  0.1792  1.1051\n",
      "-0.9923 -0.7407 -0.2055 -1.1485 -0.0656  0.6287 -0.4363  0.6943  1.0976 -1.0893\n",
      " 0.9000  0.3150 -0.2259  0.3158 -1.1373 -0.3161 -0.5774 -0.7361  0.7364 -0.0459\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0206  0.9918  0.0613  0.6832  0.2573 -0.4497 -0.7473  0.7022 -1.0860 -0.0348\n",
      "-0.0154  0.0389 -0.7777  0.9237 -0.2550  0.3187 -0.3969  0.0698  0.6850 -0.1287\n",
      " 1.2658  1.0277  0.3679  0.6995  0.0390  0.2593 -0.6425 -0.6698  0.4280 -0.3472\n",
      "-0.2981 -0.0907 -2.3458 -0.0386 -1.2049 -1.1103 -0.4567  1.3182  1.4839 -1.5535\n",
      "\n",
      "Columns 40 to 49 \n",
      "-0.0147 -1.2272  1.5646 -0.1008  1.8027 -1.7267 -0.8005 -1.0024  0.6281 -2.8517\n",
      "-1.9390 -1.8674  0.2597 -0.9365 -0.2462  0.4402 -1.2266 -1.5069 -0.8285  1.0115\n",
      " 0.1170 -0.5704 -0.3647  0.8583  0.5840 -0.1370  0.0175 -0.8416 -1.0838  1.0171\n",
      " 0.7364  1.1366 -0.2887  0.9281 -1.7317 -0.2411 -0.5388  0.8016  0.4732  0.5797\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.6289 -0.8129  0.0841  0.6757  1.0960  0.4448  1.2882 -0.1581  1.1753  0.1174\n",
      " 1.3915 -0.8014 -0.9227  0.2606 -0.1876 -0.8768 -1.2511  0.3493  1.6071 -0.0445\n",
      "-0.4590  1.0388  0.2568 -0.8173 -0.8959  0.5800 -0.2305  0.9613  0.1811  0.0339\n",
      "-0.5933  0.0813  0.6680  0.2561 -1.0700 -1.8312 -0.6012 -0.3214  1.1804 -1.1836\n",
      "\n",
      "Columns 60 to 63 \n",
      "-1.6615 -0.1007 -0.1250  0.8433\n",
      " 0.8759  0.2338  0.4690  0.1058\n",
      " 1.2698 -0.6647 -1.1937  0.6972\n",
      "-0.4198 -0.5750  0.3692 -0.1581\n",
      "[torch.cuda.FloatTensor of size 4x64 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.cuda.FloatTensor, torch.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7e18b35a038c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_fake_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mour_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mour_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAddmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.cuda.FloatTensor, torch.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "example =   netG(get_fake_image()).data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'new'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8daddb732a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36mmake_grid\u001b[0;34m(tensor, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mymaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmaps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mxmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mymaps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxmaps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mirange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'new'"
     ]
    }
   ],
   "source": [
    "utils.make_grid(our_example)\n",
    "im = example / 2 +0.5\n",
    "im = im.numpy()\n",
    "plt.imshow(np.transpose(im[2], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 0); loss_generator: 166.46466064453125; loss_discriminator:  0.7042521238327026\n",
      "step: 500 / 18026 (epoch: 0); loss_generator: 152.04891967773438; loss_discriminator:  0.5004137754440308\n",
      "step: 1000 / 18026 (epoch: 0); loss_generator: 140.39581298828125; loss_discriminator:  0.7453879117965698\n",
      "step: 1500 / 18026 (epoch: 0); loss_generator: 196.1815643310547; loss_discriminator:  0.7989851832389832\n",
      "step: 2000 / 18026 (epoch: 0); loss_generator: 99.18516540527344; loss_discriminator:  0.6927722096443176\n",
      "step: 2500 / 18026 (epoch: 0); loss_generator: 259.8188171386719; loss_discriminator:  0.6549608707427979\n",
      "step: 3000 / 18026 (epoch: 0); loss_generator: 91.48201751708984; loss_discriminator:  1.228444218635559\n",
      "step: 3500 / 18026 (epoch: 0); loss_generator: 125.49312591552734; loss_discriminator:  0.7106086611747742\n",
      "step: 4000 / 18026 (epoch: 0); loss_generator: 148.49278259277344; loss_discriminator:  0.7257953882217407\n",
      "step: 4500 / 18026 (epoch: 0); loss_generator: 191.77247619628906; loss_discriminator:  0.5034655928611755\n",
      "step: 5000 / 18026 (epoch: 0); loss_generator: 165.89076232910156; loss_discriminator:  0.7616672515869141\n",
      "step: 5500 / 18026 (epoch: 0); loss_generator: 206.48072814941406; loss_discriminator:  0.7551098465919495\n",
      "step: 6000 / 18026 (epoch: 0); loss_generator: 142.67909240722656; loss_discriminator:  0.6930457353591919\n",
      "step: 6500 / 18026 (epoch: 0); loss_generator: 126.73853302001953; loss_discriminator:  0.8603003621101379\n",
      "step: 7000 / 18026 (epoch: 0); loss_generator: 290.3251037597656; loss_discriminator:  0.6788967251777649\n",
      "step: 7500 / 18026 (epoch: 0); loss_generator: 253.7433319091797; loss_discriminator:  0.8588933348655701\n",
      "step: 8000 / 18026 (epoch: 0); loss_generator: 241.5884552001953; loss_discriminator:  0.7826493382453918\n",
      "step: 8500 / 18026 (epoch: 0); loss_generator: 123.33346557617188; loss_discriminator:  0.4737788438796997\n",
      "step: 9000 / 18026 (epoch: 0); loss_generator: 83.05823516845703; loss_discriminator:  0.6702651977539062\n",
      "step: 9500 / 18026 (epoch: 0); loss_generator: 147.8471221923828; loss_discriminator:  0.7942941188812256\n",
      "step: 10000 / 18026 (epoch: 0); loss_generator: 146.9127655029297; loss_discriminator:  0.6229967474937439\n",
      "step: 10500 / 18026 (epoch: 0); loss_generator: 107.98091125488281; loss_discriminator:  0.5842456817626953\n",
      "step: 11000 / 18026 (epoch: 0); loss_generator: 211.0930633544922; loss_discriminator:  0.853471040725708\n",
      "step: 11500 / 18026 (epoch: 0); loss_generator: 143.12498474121094; loss_discriminator:  0.652634859085083\n",
      "step: 12000 / 18026 (epoch: 0); loss_generator: 268.0921325683594; loss_discriminator:  0.8052032589912415\n",
      "step: 12500 / 18026 (epoch: 0); loss_generator: 133.37728881835938; loss_discriminator:  0.7989097237586975\n",
      "step: 13000 / 18026 (epoch: 0); loss_generator: 157.34605407714844; loss_discriminator:  0.7712439894676208\n",
      "step: 13500 / 18026 (epoch: 0); loss_generator: 185.03463745117188; loss_discriminator:  1.2603821754455566\n",
      "step: 14000 / 18026 (epoch: 0); loss_generator: 148.03114318847656; loss_discriminator:  0.7994900941848755\n",
      "step: 14500 / 18026 (epoch: 0); loss_generator: 128.9698486328125; loss_discriminator:  0.8367866277694702\n",
      "step: 15000 / 18026 (epoch: 0); loss_generator: 159.28428649902344; loss_discriminator:  0.5573068261146545\n",
      "step: 15500 / 18026 (epoch: 0); loss_generator: 208.22601318359375; loss_discriminator:  0.8244852423667908\n",
      "step: 16000 / 18026 (epoch: 0); loss_generator: 158.1500701904297; loss_discriminator:  0.9006936550140381\n",
      "step: 16500 / 18026 (epoch: 0); loss_generator: 184.3991241455078; loss_discriminator:  0.6780449151992798\n",
      "step: 17000 / 18026 (epoch: 0); loss_generator: 190.05596923828125; loss_discriminator:  0.7152518033981323\n",
      "step: 17500 / 18026 (epoch: 0); loss_generator: 135.87672424316406; loss_discriminator:  0.6933043003082275\n",
      "step: 18000 / 18026 (epoch: 0); loss_generator: 311.5372619628906; loss_discriminator:  0.8746539950370789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [4:48:39<00:00, 17319.78s/it]\n"
     ]
    }
   ],
   "source": [
    "k_t = train(1, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 0); loss_generator: 152.76568603515625; loss_discriminator:  0.9850686192512512\n",
      "step: 500 / 18026 (epoch: 0); loss_generator: 242.7380828857422; loss_discriminator:  0.6541787385940552\n",
      "step: 1000 / 18026 (epoch: 0); loss_generator: 153.3917694091797; loss_discriminator:  0.5228804349899292\n",
      "step: 1500 / 18026 (epoch: 0); loss_generator: 148.32752990722656; loss_discriminator:  0.9397426843643188\n",
      "step: 2000 / 18026 (epoch: 0); loss_generator: 199.57760620117188; loss_discriminator:  0.8151311278343201\n",
      "step: 2500 / 18026 (epoch: 0); loss_generator: 181.74307250976562; loss_discriminator:  0.7636301517486572\n",
      "step: 3000 / 18026 (epoch: 0); loss_generator: 194.0980682373047; loss_discriminator:  0.7937042713165283\n",
      "step: 3500 / 18026 (epoch: 0); loss_generator: 254.05764770507812; loss_discriminator:  0.6473513245582581\n",
      "step: 4000 / 18026 (epoch: 0); loss_generator: 221.41610717773438; loss_discriminator:  0.6990012526512146\n",
      "step: 4500 / 18026 (epoch: 0); loss_generator: 153.94039916992188; loss_discriminator:  0.7071845531463623\n",
      "step: 5000 / 18026 (epoch: 0); loss_generator: 164.56344604492188; loss_discriminator:  0.7391105890274048\n",
      "step: 5500 / 18026 (epoch: 0); loss_generator: 191.66787719726562; loss_discriminator:  0.6739621758460999\n",
      "step: 6000 / 18026 (epoch: 0); loss_generator: 176.71054077148438; loss_discriminator:  0.896250307559967\n",
      "step: 6500 / 18026 (epoch: 0); loss_generator: 173.7618408203125; loss_discriminator:  0.465026319026947\n",
      "step: 7000 / 18026 (epoch: 0); loss_generator: 113.43655395507812; loss_discriminator:  0.7130862474441528\n",
      "step: 7500 / 18026 (epoch: 0); loss_generator: 119.05374145507812; loss_discriminator:  0.6121097803115845\n",
      "step: 8000 / 18026 (epoch: 0); loss_generator: 143.88848876953125; loss_discriminator:  0.6899124383926392\n",
      "step: 8500 / 18026 (epoch: 0); loss_generator: 164.37269592285156; loss_discriminator:  0.6948474049568176\n",
      "step: 9000 / 18026 (epoch: 0); loss_generator: 142.0966033935547; loss_discriminator:  0.7315700054168701\n",
      "step: 9500 / 18026 (epoch: 0); loss_generator: 120.96636962890625; loss_discriminator:  0.4134373068809509\n",
      "step: 10000 / 18026 (epoch: 0); loss_generator: 214.18870544433594; loss_discriminator:  0.988836944103241\n",
      "step: 10500 / 18026 (epoch: 0); loss_generator: 209.78392028808594; loss_discriminator:  0.7317226529121399\n",
      "step: 11000 / 18026 (epoch: 0); loss_generator: 72.03907012939453; loss_discriminator:  0.896851122379303\n",
      "step: 11500 / 18026 (epoch: 0); loss_generator: 102.05841064453125; loss_discriminator:  0.9489138722419739\n",
      "step: 12000 / 18026 (epoch: 0); loss_generator: 184.0816650390625; loss_discriminator:  0.6467019319534302\n",
      "step: 12500 / 18026 (epoch: 0); loss_generator: 281.3511047363281; loss_discriminator:  0.8295662999153137\n",
      "step: 13000 / 18026 (epoch: 0); loss_generator: 198.50836181640625; loss_discriminator:  0.655650794506073\n",
      "step: 13500 / 18026 (epoch: 0); loss_generator: 191.84307861328125; loss_discriminator:  0.5269175171852112\n",
      "step: 14000 / 18026 (epoch: 0); loss_generator: 162.75741577148438; loss_discriminator:  0.6767590641975403\n",
      "step: 14500 / 18026 (epoch: 0); loss_generator: 115.70467376708984; loss_discriminator:  0.9214699864387512\n",
      "step: 15000 / 18026 (epoch: 0); loss_generator: 190.38006591796875; loss_discriminator:  0.7401799559593201\n",
      "step: 15500 / 18026 (epoch: 0); loss_generator: 230.62673950195312; loss_discriminator:  0.623193085193634\n",
      "step: 16000 / 18026 (epoch: 0); loss_generator: 132.75059509277344; loss_discriminator:  0.8206108808517456\n",
      "step: 16500 / 18026 (epoch: 0); loss_generator: 233.22283935546875; loss_discriminator:  0.585753858089447\n",
      "step: 17000 / 18026 (epoch: 0); loss_generator: 324.0613098144531; loss_discriminator:  0.9776896238327026\n",
      "step: 17500 / 18026 (epoch: 0); loss_generator: 257.12896728515625; loss_discriminator:  0.668096125125885\n",
      "step: 18000 / 18026 (epoch: 0); loss_generator: 260.8867492675781; loss_discriminator:  0.6956363916397095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [4:45:03<19:00:12, 17103.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 1); loss_generator: 245.5597686767578; loss_discriminator:  0.7111674547195435\n",
      "step: 500 / 18026 (epoch: 1); loss_generator: 152.02371215820312; loss_discriminator:  0.7005369663238525\n",
      "step: 1000 / 18026 (epoch: 1); loss_generator: 284.42767333984375; loss_discriminator:  0.6702275276184082\n",
      "step: 1500 / 18026 (epoch: 1); loss_generator: 211.71878051757812; loss_discriminator:  0.686380922794342\n",
      "step: 2000 / 18026 (epoch: 1); loss_generator: 104.63006591796875; loss_discriminator:  0.5644940137863159\n",
      "step: 2500 / 18026 (epoch: 1); loss_generator: 103.7384262084961; loss_discriminator:  0.6926787495613098\n",
      "step: 3000 / 18026 (epoch: 1); loss_generator: 209.03302001953125; loss_discriminator:  0.5799936652183533\n",
      "step: 3500 / 18026 (epoch: 1); loss_generator: 170.26353454589844; loss_discriminator:  0.6541498899459839\n",
      "step: 4000 / 18026 (epoch: 1); loss_generator: 114.35316467285156; loss_discriminator:  0.6606723070144653\n",
      "step: 4500 / 18026 (epoch: 1); loss_generator: 156.61244201660156; loss_discriminator:  0.5539442896842957\n",
      "step: 5000 / 18026 (epoch: 1); loss_generator: 201.0780487060547; loss_discriminator:  0.7205215692520142\n",
      "step: 5500 / 18026 (epoch: 1); loss_generator: 371.04010009765625; loss_discriminator:  0.7531915307044983\n",
      "step: 6000 / 18026 (epoch: 1); loss_generator: 161.72430419921875; loss_discriminator:  0.7983149290084839\n",
      "step: 6500 / 18026 (epoch: 1); loss_generator: 176.79820251464844; loss_discriminator:  0.6020426750183105\n",
      "step: 7000 / 18026 (epoch: 1); loss_generator: 195.18714904785156; loss_discriminator:  0.7370973229408264\n",
      "step: 7500 / 18026 (epoch: 1); loss_generator: 134.54318237304688; loss_discriminator:  0.6071498990058899\n",
      "step: 8000 / 18026 (epoch: 1); loss_generator: 122.78816986083984; loss_discriminator:  0.8447107672691345\n",
      "step: 8500 / 18026 (epoch: 1); loss_generator: 207.88629150390625; loss_discriminator:  0.6726620197296143\n",
      "step: 9000 / 18026 (epoch: 1); loss_generator: 119.3441390991211; loss_discriminator:  0.664966344833374\n",
      "step: 9500 / 18026 (epoch: 1); loss_generator: 154.89015197753906; loss_discriminator:  0.6510695815086365\n",
      "step: 10000 / 18026 (epoch: 1); loss_generator: 206.7486114501953; loss_discriminator:  0.5268664360046387\n",
      "step: 10500 / 18026 (epoch: 1); loss_generator: 243.95387268066406; loss_discriminator:  0.5472758412361145\n",
      "step: 11000 / 18026 (epoch: 1); loss_generator: 199.42198181152344; loss_discriminator:  1.1616085767745972\n",
      "step: 11500 / 18026 (epoch: 1); loss_generator: 116.4910659790039; loss_discriminator:  0.8355689644813538\n",
      "step: 12000 / 18026 (epoch: 1); loss_generator: 124.79457092285156; loss_discriminator:  0.5244885087013245\n",
      "step: 12500 / 18026 (epoch: 1); loss_generator: 94.46416473388672; loss_discriminator:  0.6238626837730408\n",
      "step: 13000 / 18026 (epoch: 1); loss_generator: 117.69719696044922; loss_discriminator:  0.7717251181602478\n",
      "step: 13500 / 18026 (epoch: 1); loss_generator: 103.39849853515625; loss_discriminator:  0.6583594679832458\n",
      "step: 14000 / 18026 (epoch: 1); loss_generator: 90.30156707763672; loss_discriminator:  0.35521969199180603\n",
      "step: 14500 / 18026 (epoch: 1); loss_generator: 56.18515396118164; loss_discriminator:  0.7080855369567871\n",
      "step: 15000 / 18026 (epoch: 1); loss_generator: 72.19992065429688; loss_discriminator:  0.7700539827346802\n",
      "step: 15500 / 18026 (epoch: 1); loss_generator: 48.30552673339844; loss_discriminator:  0.5802813172340393\n",
      "step: 16000 / 18026 (epoch: 1); loss_generator: 102.30010986328125; loss_discriminator:  0.8048075437545776\n",
      "step: 16500 / 18026 (epoch: 1); loss_generator: 61.57680130004883; loss_discriminator:  0.5804333686828613\n",
      "step: 17000 / 18026 (epoch: 1); loss_generator: 52.374267578125; loss_discriminator:  0.7463458776473999\n",
      "step: 17500 / 18026 (epoch: 1); loss_generator: 47.20085906982422; loss_discriminator:  0.5558815598487854\n",
      "step: 18000 / 18026 (epoch: 1); loss_generator: 62.066802978515625; loss_discriminator:  0.5675413608551025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [9:28:58<14:13:28, 17069.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 2); loss_generator: 72.11239624023438; loss_discriminator:  0.6932873725891113\n",
      "step: 500 / 18026 (epoch: 2); loss_generator: 62.221370697021484; loss_discriminator:  0.6323201656341553\n",
      "step: 1000 / 18026 (epoch: 2); loss_generator: 43.893123626708984; loss_discriminator:  0.5861773490905762\n",
      "step: 1500 / 18026 (epoch: 2); loss_generator: 51.514015197753906; loss_discriminator:  0.8636547923088074\n",
      "step: 2000 / 18026 (epoch: 2); loss_generator: 48.77150344848633; loss_discriminator:  0.8087961673736572\n",
      "step: 2500 / 18026 (epoch: 2); loss_generator: 43.88018035888672; loss_discriminator:  0.6392520666122437\n",
      "step: 3000 / 18026 (epoch: 2); loss_generator: 34.62308883666992; loss_discriminator:  0.8162394762039185\n",
      "step: 3500 / 18026 (epoch: 2); loss_generator: 38.735782623291016; loss_discriminator:  0.7000225782394409\n",
      "step: 4000 / 18026 (epoch: 2); loss_generator: 33.42008972167969; loss_discriminator:  0.6138095259666443\n",
      "step: 4500 / 18026 (epoch: 2); loss_generator: 34.302520751953125; loss_discriminator:  0.5417336821556091\n",
      "step: 5000 / 18026 (epoch: 2); loss_generator: 29.193105697631836; loss_discriminator:  0.6713149547576904\n",
      "step: 5500 / 18026 (epoch: 2); loss_generator: 27.31342887878418; loss_discriminator:  0.9398316740989685\n",
      "step: 6000 / 18026 (epoch: 2); loss_generator: 25.88773536682129; loss_discriminator:  0.6424870491027832\n",
      "step: 6500 / 18026 (epoch: 2); loss_generator: 24.913394927978516; loss_discriminator:  0.6237279176712036\n",
      "step: 7000 / 18026 (epoch: 2); loss_generator: 21.52150535583496; loss_discriminator:  0.7158656716346741\n",
      "step: 7500 / 18026 (epoch: 2); loss_generator: 29.78209114074707; loss_discriminator:  0.596081018447876\n",
      "step: 8000 / 18026 (epoch: 2); loss_generator: 24.17894744873047; loss_discriminator:  0.644184947013855\n",
      "step: 8500 / 18026 (epoch: 2); loss_generator: 18.263179779052734; loss_discriminator:  0.6874377727508545\n",
      "step: 9000 / 18026 (epoch: 2); loss_generator: 23.309768676757812; loss_discriminator:  0.7383933663368225\n",
      "step: 9500 / 18026 (epoch: 2); loss_generator: 12.850805282592773; loss_discriminator:  0.6637632846832275\n",
      "step: 10000 / 18026 (epoch: 2); loss_generator: 11.206177711486816; loss_discriminator:  0.690445065498352\n",
      "step: 10500 / 18026 (epoch: 2); loss_generator: 8.480001449584961; loss_discriminator:  0.7840834259986877\n",
      "step: 11000 / 18026 (epoch: 2); loss_generator: 2.7473134994506836; loss_discriminator:  0.6863423585891724\n",
      "step: 11500 / 18026 (epoch: 2); loss_generator: 2.7834949493408203; loss_discriminator:  0.4834708571434021\n",
      "step: 12000 / 18026 (epoch: 2); loss_generator: 2.6081833839416504; loss_discriminator:  0.817720890045166\n",
      "step: 12500 / 18026 (epoch: 2); loss_generator: 2.33705735206604; loss_discriminator:  1.1283204555511475\n",
      "step: 13000 / 18026 (epoch: 2); loss_generator: 2.6424131393432617; loss_discriminator:  0.9108893275260925\n",
      "step: 13500 / 18026 (epoch: 2); loss_generator: 2.3629820346832275; loss_discriminator:  0.6691256761550903\n",
      "step: 14000 / 18026 (epoch: 2); loss_generator: 2.5886168479919434; loss_discriminator:  0.4355325698852539\n",
      "step: 14500 / 18026 (epoch: 2); loss_generator: 2.49786639213562; loss_discriminator:  0.5812748074531555\n",
      "step: 15000 / 18026 (epoch: 2); loss_generator: 3.071226119995117; loss_discriminator:  1.1295523643493652\n",
      "step: 15500 / 18026 (epoch: 2); loss_generator: 2.2847673892974854; loss_discriminator:  0.662390410900116\n",
      "step: 16000 / 18026 (epoch: 2); loss_generator: 2.383709669113159; loss_discriminator:  0.7057679295539856\n",
      "step: 16500 / 18026 (epoch: 2); loss_generator: 2.26867938041687; loss_discriminator:  0.6402882933616638\n",
      "step: 17000 / 18026 (epoch: 2); loss_generator: 2.5024640560150146; loss_discriminator:  0.5089495778083801\n",
      "step: 17500 / 18026 (epoch: 2); loss_generator: 2.2816731929779053; loss_discriminator:  0.6959792971611023\n",
      "step: 18000 / 18026 (epoch: 2); loss_generator: 2.7174901962280273; loss_discriminator:  0.4414098262786865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [14:07:47<9:25:11, 16955.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 3); loss_generator: 2.4407894611358643; loss_discriminator:  0.5916203856468201\n",
      "step: 500 / 18026 (epoch: 3); loss_generator: 2.475938081741333; loss_discriminator:  0.5416665077209473\n",
      "step: 1000 / 18026 (epoch: 3); loss_generator: 2.308192253112793; loss_discriminator:  0.8677738904953003\n",
      "step: 1500 / 18026 (epoch: 3); loss_generator: 2.316596031188965; loss_discriminator:  0.846494197845459\n",
      "step: 2000 / 18026 (epoch: 3); loss_generator: 2.361809492111206; loss_discriminator:  0.7262834906578064\n",
      "step: 2500 / 18026 (epoch: 3); loss_generator: 2.414045572280884; loss_discriminator:  1.1892286539077759\n",
      "step: 3000 / 18026 (epoch: 3); loss_generator: 2.2056806087493896; loss_discriminator:  0.7528954744338989\n",
      "step: 3500 / 18026 (epoch: 3); loss_generator: 3.06121563911438; loss_discriminator:  0.5757672190666199\n",
      "step: 4000 / 18026 (epoch: 3); loss_generator: 2.605079412460327; loss_discriminator:  0.734407365322113\n",
      "step: 4500 / 18026 (epoch: 3); loss_generator: 2.681097984313965; loss_discriminator:  0.6272369027137756\n",
      "step: 5000 / 18026 (epoch: 3); loss_generator: 2.37410831451416; loss_discriminator:  0.9832109808921814\n",
      "step: 5500 / 18026 (epoch: 3); loss_generator: 2.770258903503418; loss_discriminator:  0.7343898415565491\n",
      "step: 6000 / 18026 (epoch: 3); loss_generator: 2.1673460006713867; loss_discriminator:  0.6210659146308899\n",
      "step: 6500 / 18026 (epoch: 3); loss_generator: 2.381460189819336; loss_discriminator:  0.6718078851699829\n",
      "step: 7000 / 18026 (epoch: 3); loss_generator: 2.912710189819336; loss_discriminator:  0.6926685571670532\n",
      "step: 7500 / 18026 (epoch: 3); loss_generator: 2.3401107788085938; loss_discriminator:  0.5968502759933472\n",
      "step: 8000 / 18026 (epoch: 3); loss_generator: 2.4651336669921875; loss_discriminator:  0.7014392614364624\n",
      "step: 8500 / 18026 (epoch: 3); loss_generator: 2.512389659881592; loss_discriminator:  0.5216710567474365\n",
      "step: 9000 / 18026 (epoch: 3); loss_generator: 2.3219246864318848; loss_discriminator:  0.7670683264732361\n",
      "step: 9500 / 18026 (epoch: 3); loss_generator: 2.629560947418213; loss_discriminator:  0.4780256450176239\n",
      "step: 10000 / 18026 (epoch: 3); loss_generator: 2.1608922481536865; loss_discriminator:  0.7839918732643127\n",
      "step: 10500 / 18026 (epoch: 3); loss_generator: 2.269881248474121; loss_discriminator:  0.6031801700592041\n",
      "step: 11000 / 18026 (epoch: 3); loss_generator: 2.5389955043792725; loss_discriminator:  0.5759184956550598\n",
      "step: 11500 / 18026 (epoch: 3); loss_generator: 2.263338565826416; loss_discriminator:  0.8092845678329468\n",
      "step: 12000 / 18026 (epoch: 3); loss_generator: 2.539633274078369; loss_discriminator:  0.6633215546607971\n",
      "step: 12500 / 18026 (epoch: 3); loss_generator: 2.6981356143951416; loss_discriminator:  0.4406951367855072\n",
      "step: 13000 / 18026 (epoch: 3); loss_generator: 2.7579548358917236; loss_discriminator:  0.9998588562011719\n",
      "step: 13500 / 18026 (epoch: 3); loss_generator: 2.548558235168457; loss_discriminator:  0.5445288419723511\n",
      "step: 14000 / 18026 (epoch: 3); loss_generator: 2.38900089263916; loss_discriminator:  0.9032407402992249\n",
      "step: 14500 / 18026 (epoch: 3); loss_generator: 2.2136876583099365; loss_discriminator:  0.6853806376457214\n",
      "step: 15000 / 18026 (epoch: 3); loss_generator: 2.5136499404907227; loss_discriminator:  0.810060977935791\n",
      "step: 15500 / 18026 (epoch: 3); loss_generator: 2.3510286808013916; loss_discriminator:  0.8657217621803284\n",
      "step: 16000 / 18026 (epoch: 3); loss_generator: 2.4502992630004883; loss_discriminator:  0.6976931691169739\n",
      "step: 16500 / 18026 (epoch: 3); loss_generator: 2.2255167961120605; loss_discriminator:  0.6984206438064575\n",
      "step: 17000 / 18026 (epoch: 3); loss_generator: 2.432335138320923; loss_discriminator:  0.7059672474861145\n",
      "step: 17500 / 18026 (epoch: 3); loss_generator: 2.1569595336914062; loss_discriminator:  0.5912056565284729\n",
      "step: 18000 / 18026 (epoch: 3); loss_generator: 2.080449104309082; loss_discriminator:  0.6411730647087097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [18:46:03<4:41:30, 16890.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 4); loss_generator: 1.9692747592926025; loss_discriminator:  0.7406948804855347\n",
      "step: 500 / 18026 (epoch: 4); loss_generator: 0.3573513329029083; loss_discriminator:  0.621408998966217\n",
      "step: 1000 / 18026 (epoch: 4); loss_generator: 0.5666595101356506; loss_discriminator:  0.5416548252105713\n",
      "step: 1500 / 18026 (epoch: 4); loss_generator: 0.16864798963069916; loss_discriminator:  0.7562864422798157\n",
      "step: 2000 / 18026 (epoch: 4); loss_generator: 0.40758147835731506; loss_discriminator:  0.6242110133171082\n",
      "step: 2500 / 18026 (epoch: 4); loss_generator: 0.593187689781189; loss_discriminator:  0.818086564540863\n",
      "step: 3000 / 18026 (epoch: 4); loss_generator: 0.5606679916381836; loss_discriminator:  0.5186317563056946\n",
      "step: 3500 / 18026 (epoch: 4); loss_generator: 0.4026111662387848; loss_discriminator:  0.7792162299156189\n",
      "step: 4000 / 18026 (epoch: 4); loss_generator: 0.2733788788318634; loss_discriminator:  0.6123334169387817\n",
      "step: 4500 / 18026 (epoch: 4); loss_generator: 0.3351338803768158; loss_discriminator:  0.49192243814468384\n",
      "step: 5000 / 18026 (epoch: 4); loss_generator: 0.47541680932044983; loss_discriminator:  0.493714302778244\n",
      "step: 5500 / 18026 (epoch: 4); loss_generator: 0.5438646078109741; loss_discriminator:  0.5581976771354675\n",
      "step: 6000 / 18026 (epoch: 4); loss_generator: 0.5697444081306458; loss_discriminator:  0.5869250297546387\n",
      "step: 6500 / 18026 (epoch: 4); loss_generator: 0.516794741153717; loss_discriminator:  0.6901348829269409\n",
      "step: 7000 / 18026 (epoch: 4); loss_generator: 0.7208027839660645; loss_discriminator:  0.8187515139579773\n",
      "step: 7500 / 18026 (epoch: 4); loss_generator: 0.8353267908096313; loss_discriminator:  0.48082947731018066\n",
      "step: 8000 / 18026 (epoch: 4); loss_generator: 0.38932090997695923; loss_discriminator:  0.6116604804992676\n",
      "step: 8500 / 18026 (epoch: 4); loss_generator: 0.3665883243083954; loss_discriminator:  0.8860961198806763\n",
      "step: 9000 / 18026 (epoch: 4); loss_generator: 0.4068433344364166; loss_discriminator:  0.8032978773117065\n",
      "step: 9500 / 18026 (epoch: 4); loss_generator: 0.4527536928653717; loss_discriminator:  0.44985049962997437\n",
      "step: 10000 / 18026 (epoch: 4); loss_generator: 0.5424063801765442; loss_discriminator:  0.8350767493247986\n",
      "step: 10500 / 18026 (epoch: 4); loss_generator: 0.26708462834358215; loss_discriminator:  0.8087542653083801\n",
      "step: 11000 / 18026 (epoch: 4); loss_generator: 0.9727802276611328; loss_discriminator:  0.5757334232330322\n",
      "step: 11500 / 18026 (epoch: 4); loss_generator: 0.617975115776062; loss_discriminator:  0.8888636231422424\n",
      "step: 12000 / 18026 (epoch: 4); loss_generator: 0.29343321919441223; loss_discriminator:  0.5993998646736145\n",
      "step: 12500 / 18026 (epoch: 4); loss_generator: 0.44515401124954224; loss_discriminator:  0.6362707614898682\n",
      "step: 13000 / 18026 (epoch: 4); loss_generator: 0.4428155720233917; loss_discriminator:  0.9316810369491577\n",
      "step: 13500 / 18026 (epoch: 4); loss_generator: 0.44420531392097473; loss_discriminator:  0.6170971989631653\n",
      "step: 14000 / 18026 (epoch: 4); loss_generator: 0.7504382133483887; loss_discriminator:  1.0178377628326416\n",
      "step: 14500 / 18026 (epoch: 4); loss_generator: 0.22709669172763824; loss_discriminator:  0.4960215389728546\n",
      "step: 15000 / 18026 (epoch: 4); loss_generator: 0.7086964845657349; loss_discriminator:  0.6245458126068115\n",
      "step: 15500 / 18026 (epoch: 4); loss_generator: 0.5700423121452332; loss_discriminator:  0.7321207523345947\n",
      "step: 16000 / 18026 (epoch: 4); loss_generator: 0.3928096294403076; loss_discriminator:  0.4765535295009613\n",
      "step: 16500 / 18026 (epoch: 4); loss_generator: 0.12560419738292694; loss_discriminator:  0.7341297268867493\n",
      "step: 17000 / 18026 (epoch: 4); loss_generator: 0.7439960241317749; loss_discriminator:  0.5858012437820435\n",
      "step: 17500 / 18026 (epoch: 4); loss_generator: 0.6994470953941345; loss_discriminator:  0.5941455960273743\n",
      "step: 18000 / 18026 (epoch: 4); loss_generator: 0.36047595739364624; loss_discriminator:  0.7043129801750183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [23:17:33<00:00, 16770.67s/it]  \n"
     ]
    }
   ],
   "source": [
    "k_t = train(5, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 0); loss_generator: 0.9846611022949219; loss_discriminator:  0.9037147164344788\n",
      "step: 500 / 18026 (epoch: 0); loss_generator: 0.6578286290168762; loss_discriminator:  0.7423400282859802\n",
      "step: 1000 / 18026 (epoch: 0); loss_generator: 0.6028868556022644; loss_discriminator:  0.6143257021903992\n",
      "step: 1500 / 18026 (epoch: 0); loss_generator: 0.5542176961898804; loss_discriminator:  0.5053091049194336\n",
      "step: 2000 / 18026 (epoch: 0); loss_generator: 0.29155218601226807; loss_discriminator:  1.031799554824829\n",
      "step: 2500 / 18026 (epoch: 0); loss_generator: 0.545762300491333; loss_discriminator:  0.560034453868866\n",
      "step: 3000 / 18026 (epoch: 0); loss_generator: 0.1861163079738617; loss_discriminator:  0.5635674595832825\n",
      "step: 3500 / 18026 (epoch: 0); loss_generator: 0.4809657633304596; loss_discriminator:  0.6846194863319397\n",
      "step: 4000 / 18026 (epoch: 0); loss_generator: 0.38454487919807434; loss_discriminator:  0.8265624046325684\n",
      "step: 4500 / 18026 (epoch: 0); loss_generator: 0.23674431443214417; loss_discriminator:  0.8264005780220032\n",
      "step: 5000 / 18026 (epoch: 0); loss_generator: 0.2979150116443634; loss_discriminator:  0.7589067816734314\n",
      "step: 5500 / 18026 (epoch: 0); loss_generator: 0.41217416524887085; loss_discriminator:  0.7344181537628174\n",
      "step: 6000 / 18026 (epoch: 0); loss_generator: 0.9112992286682129; loss_discriminator:  0.48541247844696045\n",
      "step: 6500 / 18026 (epoch: 0); loss_generator: 0.6772816777229309; loss_discriminator:  0.5917075276374817\n",
      "step: 7000 / 18026 (epoch: 0); loss_generator: 0.4332740902900696; loss_discriminator:  0.681011974811554\n",
      "step: 7500 / 18026 (epoch: 0); loss_generator: 0.6462486386299133; loss_discriminator:  0.6968886256217957\n",
      "step: 8000 / 18026 (epoch: 0); loss_generator: 0.09209346771240234; loss_discriminator:  0.45887163281440735\n",
      "step: 8500 / 18026 (epoch: 0); loss_generator: 0.7796735167503357; loss_discriminator:  1.1340203285217285\n",
      "step: 9000 / 18026 (epoch: 0); loss_generator: 0.2782667577266693; loss_discriminator:  0.6959930658340454\n",
      "step: 9500 / 18026 (epoch: 0); loss_generator: 0.20121115446090698; loss_discriminator:  0.7289865016937256\n",
      "step: 10000 / 18026 (epoch: 0); loss_generator: 0.48546722531318665; loss_discriminator:  0.6620824337005615\n",
      "step: 10500 / 18026 (epoch: 0); loss_generator: 0.5497424006462097; loss_discriminator:  0.6186491250991821\n",
      "step: 11000 / 18026 (epoch: 0); loss_generator: 0.3797124922275543; loss_discriminator:  0.6520492434501648\n",
      "step: 11500 / 18026 (epoch: 0); loss_generator: 0.6451100707054138; loss_discriminator:  0.7528155446052551\n",
      "step: 12000 / 18026 (epoch: 0); loss_generator: 0.5106611251831055; loss_discriminator:  0.6079132556915283\n",
      "step: 12500 / 18026 (epoch: 0); loss_generator: 0.29228273034095764; loss_discriminator:  0.7020331025123596\n",
      "step: 13000 / 18026 (epoch: 0); loss_generator: 0.14524704217910767; loss_discriminator:  0.5485457181930542\n",
      "step: 13500 / 18026 (epoch: 0); loss_generator: 0.5386517643928528; loss_discriminator:  0.7755218148231506\n",
      "step: 14000 / 18026 (epoch: 0); loss_generator: 0.6338444948196411; loss_discriminator:  0.8869978785514832\n",
      "step: 14500 / 18026 (epoch: 0); loss_generator: 0.14100727438926697; loss_discriminator:  0.6186348795890808\n",
      "step: 15000 / 18026 (epoch: 0); loss_generator: 0.8729438185691833; loss_discriminator:  0.7704758644104004\n",
      "step: 15500 / 18026 (epoch: 0); loss_generator: 0.37730827927589417; loss_discriminator:  0.6378896832466125\n",
      "step: 16000 / 18026 (epoch: 0); loss_generator: 0.35089513659477234; loss_discriminator:  0.47278571128845215\n",
      "step: 16500 / 18026 (epoch: 0); loss_generator: 0.5719031691551208; loss_discriminator:  0.9101460576057434\n",
      "step: 17000 / 18026 (epoch: 0); loss_generator: 0.6478481292724609; loss_discriminator:  0.7471498250961304\n",
      "step: 17500 / 18026 (epoch: 0); loss_generator: 1.0061392784118652; loss_discriminator:  0.6656617522239685\n",
      "step: 18000 / 18026 (epoch: 0); loss_generator: 0.6331543326377869; loss_discriminator:  0.7531627416610718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [4:31:36<4:31:36, 16296.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 / 18026 (epoch: 1); loss_generator: 0.6861345767974854; loss_discriminator:  0.6764991283416748\n",
      "step: 500 / 18026 (epoch: 1); loss_generator: 0.3599548041820526; loss_discriminator:  0.5012069344520569\n",
      "step: 1000 / 18026 (epoch: 1); loss_generator: 0.3781839907169342; loss_discriminator:  0.5807846784591675\n",
      "step: 1500 / 18026 (epoch: 1); loss_generator: 0.4132028818130493; loss_discriminator:  0.7366970181465149\n",
      "step: 2000 / 18026 (epoch: 1); loss_generator: 0.5257691144943237; loss_discriminator:  0.7179930806159973\n",
      "step: 2500 / 18026 (epoch: 1); loss_generator: 0.3107345700263977; loss_discriminator:  0.6806625723838806\n",
      "step: 3000 / 18026 (epoch: 1); loss_generator: 0.3080165982246399; loss_discriminator:  0.7395042777061462\n",
      "step: 3500 / 18026 (epoch: 1); loss_generator: 0.41070854663848877; loss_discriminator:  0.5791465640068054\n",
      "step: 4000 / 18026 (epoch: 1); loss_generator: 0.522341787815094; loss_discriminator:  0.6909742951393127\n",
      "step: 4500 / 18026 (epoch: 1); loss_generator: 0.2074420005083084; loss_discriminator:  0.613158106803894\n",
      "step: 5000 / 18026 (epoch: 1); loss_generator: 0.4649679958820343; loss_discriminator:  0.5823414325714111\n",
      "step: 5500 / 18026 (epoch: 1); loss_generator: 0.2895630896091461; loss_discriminator:  0.6608020663261414\n",
      "step: 6000 / 18026 (epoch: 1); loss_generator: 0.8650692105293274; loss_discriminator:  0.6714198589324951\n",
      "step: 6500 / 18026 (epoch: 1); loss_generator: 0.7336564064025879; loss_discriminator:  0.6009388566017151\n",
      "step: 7000 / 18026 (epoch: 1); loss_generator: 0.2619507312774658; loss_discriminator:  0.941088855266571\n",
      "step: 7500 / 18026 (epoch: 1); loss_generator: 0.6200605034828186; loss_discriminator:  0.5492871403694153\n",
      "step: 8000 / 18026 (epoch: 1); loss_generator: 0.2684711813926697; loss_discriminator:  0.65294349193573\n",
      "step: 8500 / 18026 (epoch: 1); loss_generator: 0.21872685849666595; loss_discriminator:  0.7220826745033264\n",
      "step: 9000 / 18026 (epoch: 1); loss_generator: 0.22774530947208405; loss_discriminator:  0.7443580031394958\n",
      "step: 9500 / 18026 (epoch: 1); loss_generator: 1.2456841468811035; loss_discriminator:  1.3735803365707397\n",
      "step: 10000 / 18026 (epoch: 1); loss_generator: 0.7507261633872986; loss_discriminator:  0.6529983282089233\n",
      "step: 10500 / 18026 (epoch: 1); loss_generator: 0.5202041268348694; loss_discriminator:  0.8206459283828735\n",
      "step: 11000 / 18026 (epoch: 1); loss_generator: 0.6535361409187317; loss_discriminator:  0.8080787062644958\n",
      "step: 11500 / 18026 (epoch: 1); loss_generator: 0.44411224126815796; loss_discriminator:  1.022385597229004\n",
      "step: 12000 / 18026 (epoch: 1); loss_generator: 0.1645834743976593; loss_discriminator:  0.7235520482063293\n",
      "step: 12500 / 18026 (epoch: 1); loss_generator: 0.40033408999443054; loss_discriminator:  0.5767922401428223\n",
      "step: 13000 / 18026 (epoch: 1); loss_generator: 0.43409639596939087; loss_discriminator:  0.660607099533081\n",
      "step: 13500 / 18026 (epoch: 1); loss_generator: 0.6442420482635498; loss_discriminator:  0.6904066205024719\n",
      "step: 14000 / 18026 (epoch: 1); loss_generator: 0.24606631696224213; loss_discriminator:  0.6305673122406006\n",
      "step: 14500 / 18026 (epoch: 1); loss_generator: 0.4960610568523407; loss_discriminator:  0.6309778690338135\n",
      "step: 15000 / 18026 (epoch: 1); loss_generator: 0.5200620293617249; loss_discriminator:  0.6796804070472717\n",
      "step: 15500 / 18026 (epoch: 1); loss_generator: 0.950017511844635; loss_discriminator:  0.620331883430481\n",
      "step: 16000 / 18026 (epoch: 1); loss_generator: 0.6596190333366394; loss_discriminator:  0.9805063009262085\n",
      "step: 16500 / 18026 (epoch: 1); loss_generator: 1.2619692087173462; loss_discriminator:  1.2009236812591553\n",
      "step: 17000 / 18026 (epoch: 1); loss_generator: 0.10611212998628616; loss_discriminator:  0.4572400450706482\n",
      "step: 17500 / 18026 (epoch: 1); loss_generator: 0.5519976615905762; loss_discriminator:  0.7865483164787292\n",
      "step: 18000 / 18026 (epoch: 1); loss_generator: 0.22637838125228882; loss_discriminator:  0.9909166693687439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [9:02:43<00:00, 16281.95s/it]  \n"
     ]
    }
   ],
   "source": [
    "k_t = train(2, k_t, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd27677fef0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAAD8CAYAAABpe3YUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4zWwryH3ZeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd276ac5940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example =   netG(get_fake_image()).data.cpu()\n",
    "utils.make_grid(example)\n",
    "im = example / 2 +0.5\n",
    "im = im.numpy()\n",
    "plt.imshow(np.transpose(im[2], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
