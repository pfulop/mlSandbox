{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset \n",
    "import glob\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 36\n",
    "height = 64\n",
    "emb_w = math.ceil(width / 4)\n",
    "emb_h = math.ceil(height / 4)\n",
    "np.random.seed(1)\n",
    "h= 64\n",
    "n = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/run/media/backman/yay/uiD'\n",
    "MODEL2_PATH = '/run/media/backman/yay/uiG'\n",
    "\n",
    "def save_model():\n",
    "    torch.save(netD.state_dict(), MODEL_PATH)\n",
    "    torch.save(netG.state_dict(), MODEL2_PATH)\n",
    "    \n",
    "def load_model():\n",
    "    netD.load_state_dict(torch.load(MODEL_PATH))\n",
    "    netG.load_state_dict(torch.load(MODEL2_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images():\n",
    "    root_dir = '/run/media/backman/yay/unique_uis/combined/'\n",
    "    new_dir = '/run/media/backman/yay/unique_uis/resized/'\n",
    "    files = glob.glob(root_dir + '*.jpg')\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            im = Image.open(file)\n",
    "            im.thumbnail((width,height), Image.ANTIALIAS)\n",
    "            assert im.size == (width,height)\n",
    "            im.save(new_dir+os.path.basename(file),\"JPEG\")\n",
    "        except IOError:\n",
    "            pass\n",
    "        except AssertionError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleUIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, max = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = glob.glob(root_dir + '*.jpg')\n",
    "        if max:\n",
    "            self.files = np.random.permutation(self.files)[:max]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.files[idx])\n",
    "        image = io.imread(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, tuple)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w), mode='constant')\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GoogleUIDataset('/run/media/backman/yay/unique_uis/resized/',\n",
    "                                                   transform=transforms.Compose([\n",
    "#                                                     Rescale((36, 64)),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                                   ]),\n",
    "                  max=10000)\n",
    "guid = torch.utils.data.DataLoader(g,\n",
    "                                   bs, True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('ConvTranspose2d') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 4*n, emb_h, emb_w)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_sub_block(in_c, out_c, sub = False):\n",
    "    conv_sub_arr = []\n",
    "    conv_sub_arr.append(nn.Conv2d(in_c, out_c, 3, padding=1, bias=False))\n",
    "    conv_sub_arr.append(nn.LeakyReLU())\n",
    "#         conv_sub_arr.append(nn.Conv2d(out_c, out_c, 3, padding=1, bias=False))\n",
    "#         conv_sub_arr.append(nn.ReLU())\n",
    "    if sub:\n",
    "        conv_sub_arr.append(nn.Conv2d(out_c, out_c, 3, stride = 2, padding=1, bias=False))\n",
    "        conv_sub_arr.append(nn.LeakyReLU())\n",
    "        conv_sub_arr.append(torch.nn.Dropout())\n",
    "        \n",
    "    conv_sub_arr.append(nn.BatchNorm2d(out_c))\n",
    "    return conv_sub_arr\n",
    "\n",
    "def deconv_up_block(in_c, out_c = None, up = False):\n",
    "    if out_c is None:\n",
    "        out_c = in_c\n",
    "    deconv_sub_arr = []\n",
    "    if up:\n",
    "        deconv_sub_arr.append(nn.Dropout())\n",
    "\n",
    "    deconv_sub_arr.append(nn.Conv2d(in_c, out_c, 3, padding=1, bias=False))\n",
    "    deconv_sub_arr.append(nn.LeakyReLU())\n",
    "#         deconv_sub_arr.append(nn.Conv2d(out_c, out_c, 3, padding=1, bias=False))\n",
    "#         deconv_sub_arr.append(nn.ReLU())\n",
    "    if up:\n",
    "        deconv_sub_arr.append(nn.ConvTranspose2d(out_c, out_c, 2, 2, bias=False))\n",
    "#         deconv_sub_arr.append(nn.Upsample(scale_factor = 2, mode='nearest'))\n",
    "        deconv_sub_arr.append(nn.LeakyReLU())\n",
    "    return deconv_sub_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "\n",
    "  \n",
    "\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3, n, 3, padding=1, bias=False))\n",
    "        layers += conv_sub_block(n, n*2, True)\n",
    "        layers += conv_sub_block(n*2, n*4, True)\n",
    "#         layers += self.conv_sub_block(n*3, n*4, True)\n",
    "#         layers += self.conv_sub_block(n*4, n*5, True)\n",
    "#         layers += self.conv_sub_block(n*5, n*6, True)\n",
    "#         layers += self.conv_sub_block(n*6, n*7, True)\n",
    "        layers += conv_sub_block(n*4, n*4)\n",
    "        layers.append(Flatten())\n",
    "        layers.append(nn.Linear(4*emb_h*emb_w*n, h))\n",
    " \n",
    "        layers.append(nn.Linear(h,emb_h*emb_w*n*4))\n",
    "        layers.append(Reshape())\n",
    "#         layers += self.deconv_up_block(n*7, n*6, up = True)\n",
    "#         layers += self.deconv_up_block(n*6, n*5, True)\n",
    "#         layers += self.deconv_up_block(n*5, n*4, True)\n",
    "#         layers += self.deconv_up_block(n*4, n*3, True)\n",
    "        layers += deconv_up_block(n*4, n*2, True)\n",
    "        layers += deconv_up_block(n*2, n*2, True)\n",
    "        layers += deconv_up_block(n*2, n)\n",
    "        layers.append(nn.Conv2d(n, 3, 3, padding=1, bias=False))\n",
    "        layers.append(nn.Tanh())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(h,4*emb_h*emb_w*n)) \n",
    "        layers.append(Reshape())\n",
    "#         layers += self.deconv_up_block(n*7, n*6, up = True)\n",
    "#         layers += self.deconv_up_block(n*6, n*5, True)\n",
    "#         layers += self.deconv_up_block(n*5, n*4, True)\n",
    "#         layers += self.deconv_up_block(n*4, n*3, True)\n",
    "        layers += deconv_up_block(n*4, n*2, True)\n",
    "        layers += deconv_up_block(n*2, n*2, True)\n",
    "        layers += deconv_up_block(n*2, n)\n",
    "        layers.append(nn.Conv2d(n, 3, 3, padding=1, bias=False))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = dtype(bs, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D (\n",
       "  (model): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): LeakyReLU (0.01)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): LeakyReLU (0.01)\n",
       "    (5): Dropout (p = 0.5)\n",
       "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): LeakyReLU (0.01)\n",
       "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): LeakyReLU (0.01)\n",
       "    (11): Dropout (p = 0.5)\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (14): LeakyReLU (0.01)\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (16): Flatten (\n",
       "    )\n",
       "    (17): Linear (36864 -> 64)\n",
       "    (18): Linear (64 -> 36864)\n",
       "    (19): Reshape (\n",
       "    )\n",
       "    (20): Dropout (p = 0.5)\n",
       "    (21): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (22): LeakyReLU (0.01)\n",
       "    (23): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (24): LeakyReLU (0.01)\n",
       "    (25): Dropout (p = 0.5)\n",
       "    (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (27): LeakyReLU (0.01)\n",
       "    (28): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (29): LeakyReLU (0.01)\n",
       "    (30): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (31): LeakyReLU (0.01)\n",
       "    (32): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (33): Tanh ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    netG = netG.cuda()\n",
    "    netD = netD.cuda()\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(netG.parameters(), lr =lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Variable(noise)\n",
    "ms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_image(batch):\n",
    "    var = batch\n",
    "    if use_cuda:\n",
    "        var = var.cuda()\n",
    "    return Variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_image():\n",
    "    noise.data.normal_(0, 1)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(net):\n",
    "    example =   net(get_fake_image()).data.cpu()\n",
    "    utils.make_grid(example)\n",
    "    im = example / 2 +0.5\n",
    "    im = im.numpy()\n",
    "    plt.imshow(np.transpose(im[1], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val): \n",
    "    for p in net.parameters(): p.requires_grad = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs = 1, k_t = 0, lambda_k = 0.001, gamma = 0.5):\n",
    "    n_batches = len(guid)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        data_iter = iter(guid)\n",
    "        step = 0\n",
    "        n = len(guid)\n",
    "        while step < n:\n",
    "            max_D_train = 5 if n - step >= 5 else 1 \n",
    "#             for _ in range(max_D_train):\n",
    "            image = next(data_iter)\n",
    "            step += 1\n",
    "            #real image\n",
    "            real = get_real_image(image)\n",
    "            netD.zero_grad()\n",
    "            loss_real = torch.mean(torch.abs(netD(real) - real))\n",
    "\n",
    "            #fake image\n",
    "            fake = netG(get_fake_image())\n",
    "            loss_fake = torch.mean(torch.abs(netD(fake) - fake))\n",
    "            loss_discriminator = loss_real - k_t * loss_fake\n",
    "            loss_discriminator.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            make_trainable(netD, False)\n",
    "\n",
    "            netG.zero_grad()\n",
    "            #discriminator should not be trainable here\n",
    "            fake = get_fake_image()\n",
    "            loss_generator = torch.mean(torch.abs(netG(fake) - netD(netG(fake))))\n",
    "            loss_generator.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "            update = gamma * loss_real - loss_generator\n",
    "            m = loss_real + update\n",
    "            update = update.data[0]\n",
    "            \n",
    "            k_t += lambda_k * update \n",
    "            k_t = max(min(1, k_t), 0)#bout ingore?\n",
    "            \n",
    "            make_trainable(netD, True)\n",
    "            \n",
    "        m = m.data[0]\n",
    "        ms.append(m)\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == n_epochs - 1:\n",
    "            print(f'loss_generator: {loss_generator.data[0]};\\\n",
    "                  m: {m};\\\n",
    "                  loss_discriminator:  {loss_discriminator.data[0]}')\n",
    "                \n",
    "    return k_t\n",
    "                \n",
    "            \n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:50<00:00, 110.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_generator: 0.10315725207328796;                  m: 0.22952982783317566;                  loss_discriminator:  0.22176089882850647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k_t = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAAD8CAYAAABpe3YUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw2dpHD5L4/BZmv8BC16+VxwSQzkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12352c0a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:53<01:53, 113.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_generator: 0.1058863177895546;                  m: 0.1688733696937561;                  loss_discriminator:  0.18317312002182007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [03:47<00:00, 113.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_generator: 0.11051622778177261;                  m: 0.20991960167884827;                  loss_discriminator:  0.21356049180030823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k_t = train(2, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAAD8CAYAAABpe3YUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACvFJREFUeJzt3X+o3XUdx/Hnq/1Ib9quMxvTjTZpKPsjpwx/oAhpi2GR\n/SFjEiExGESFUlCzIBD6I/vD8q/iopZ/mLr8gSKirTWJIOammzY356Yobkxn5UXrQjV798f3Mz1e\ndu6+537POW/POa8HHO73+71nfN9yX34+31/nfRQRmGX4WHYBNrocPkvj8Fkah8/SOHyWxuGzNA6f\npWkUPklrJe2XdFDSpm4VZaNBs73ILGkO8BKwBjgE7ACuj4i93SvPhtncBv/2YuBgRLwCIOk+4Fqg\nbfjGxsZifHy8wS5tEExOTjI1NaWTva9J+M4BXm9ZPwRcMtM/GB8fZ+PGjQ12aYNgYmKi1vt6fsIh\naaOknZJ2Tk1N9Xp3NkCahO8wsLRlfUnZ9iERMRERqyNi9djYWIPdDQe1vEZdk/DtAFZIWi5pPrAe\neLQ7ZdkomPUxX0Qck/Rt4ElgDnBXRLzQtcps6DU54SAiHgce71ItNmIahc8650d3P+Dba5bG4bM0\nedPu9PnH1x5Gjkc+S+PwWRqHz9KkHfNp2jGeL0GMHo98lsbhszS+w2EdaT1aanqo5JHP0jh8liZt\n2vXZ7WDq5t/NI5+lcfgsjcNnaXyppRdaD4z8tE5bHvksjcNnaTzt9oKn2lo88lkah8/SOHyWJu9h\n0mnrw3S7rZtPfgyzk458ku6SdFTSnpZtCyVtkXSg/Dyjt2XaMKoz7f4GWDtt2yZga0SsALaWdbOO\nnDR8EfEn4B/TNl8L3F2W7wa+2umOY9prmAzrf1e3zfaEY1FEHCnLbwCLulSPjZDGZ7tRdRRv+z+5\nO5NaO7MN35uSFgOUn0fbvdGdSa2d2YbvUeCGsnwD8Eh3yrFRUudSy73AX4DzJB2StAH4KbBG0gHg\nC2XdrCMnvcgcEde3+dXVXa7FRoyfarGO+HO7NhQcPkvjaXeUtJsnZ3j4tZfPxXrkszQOn6Vx+CyN\nj/lGiNqszHTJpJdP5njkszQOn6XxtDtK2l43yflGHo98lsbhszSedkdI+zPXnP4eHvksjcNnaRw+\nS+PwWRqHz9I4fJbG4bM0Dp+lcfgsjcNnaQbu9pq7fg6POu0ylkraJmmvpBck3Vi2uzupNVJn2j0G\nfC8iVgKXAt+StBJ3J7WG6nQmPRIRz5bld4F9wDl0oTvpbLjr5/Do6IRD0jLgQmA77k5qDdUOn6TT\ngAeBmyLindbfzdSd1J1JrZ1a4ZM0jyp490TEQ2Vzre6k7kxq7dQ52xVwJ7AvIm5r+VVKd1K1vGyw\n1bnOdznwdeCvknaXbT+k6ka6uXQqfQ1Y15sSbVjV6Uz6Z9oPNO5OarM2cHc4fIllePjerqVx+CyN\nw2dpHD5L4/BZGofP0jh8lsbhszQOn6UZuDscH7rF4acLBppHPkvj8Fkah8/SDN4xn4/zhoZHPkvj\n8FmagZt23S5jeHjkszQOn6UZuGnXU+3w8MhnaRw+S+PwWZqBO+YbONMOUlXz6+VHQZ1eLadIelrS\nc6Uz6S1l+3JJ2yUdlHS/pPm9L9eGSZ1p99/AVRFxAbAKWCvpUuBW4OcR8VngbWBD78q0YVSnM2lE\nxD/L6rzyCuAq4IGyvW+dSQeN9OGXfaBuf745pUPVUWAL8DIwGRHHylsOUbXKNautVvgi4r2IWAUs\nAS4Gzq+7A3cmtXY6utQSEZPANuAyYFzS8bPlJcDhNv/GnUnthOqc7Z4labwsnwqsoepIvw24rryt\nb51JB4G7p9ZT5zrfYuBuSXOowro5Ih6TtBe4T9JPgF1UrXPNaqvTmfR5qq8/mL79FarjP7NZ8R2O\nHhj1Oxd1+d6upXH4LI2n3ZlMnz99+tpVHvksjcNnaRw+S+PwWRqHz9I4fJbGl1pmMP3hT9+56C6P\nfJbG4bM0Dp+l8THfDHyM11se+SyNw2dpHD5L4/BZGofP0jh8lsbhszQOn6Vx+CyNw2dpaoevtEnb\nJemxsu7OpNZIJyPfjVQNgo5zZ1JrpG5zyCXAl4A7yrpwZ1JrqO7I9wvg+8D/yvqZuDOpNVSnP9+X\ngaMR8cxsduDOpNZOnef5Lge+Iuka4BTgk8DtlM6kZfSbsTMpMAFw9tln+xE5e1+dbvQ3R8SSiFgG\nrAf+GBFfw51JraEm1/l+AHxX0kGqY0B3JrWOdPQYfUQ8BTxVlt2Z1BrxHQ5L4/BZGofP0jh8lsbh\nszQOn6Vx+CyNw2dpHD5L4/BZGofP0jh8lsbhszQOn6Vx+CyNw2dpHD5L4/BZGofP0jh8lsbhszQO\nn6Vx+CyNw2dpHD5LU6tjgaRXgXeB94BjEbFa0kLgfmAZ8CqwLiLe7k2ZNow6Gfk+HxGrImJ1Wd8E\nbI2IFcDWsm5WW5Np91qqjqTgzqQ2C3XDF8DvJT0jaWPZtigijpTlN4BFXa/OhlrdLlVXRMRhSZ8G\ntkh6sfWXERGSTtj4sYR1I8CCBQsaFWvDpdbIFxGHy8+jwMNUrdHelLQYoPw82ubfTkTE6ohYPTY2\n1p2qbSjU6cn8CUmnH18GvgjsAR6l6kgK7kxqs1Bn2l0EPFx9+wFzgd9GxBOSdgCbJW0AXgPW9a5M\nG0YnDV/pQHrBCbb/Hbi6F0XZaPAdDkvj8Fkah8/SOHyWpqOvQjBTy3LTr5PyyGdpHD5L42nXOtLN\nb270yGdpHD5L4/BZGofP0jh8lsbhszQOn6Vx+CyNw2dpfIfDOuIHC2woOHyWxuGzND7ms474qRYb\nCg6fpXH4LE2t8Ekal/SApBcl7ZN0maSFkrZIOlB+ntHrYm241B35bgeeiIjzqVpn7MOdSa2hOl2q\nFgBXAncCRMR/ImISdya1huqMfMuBt4BfS9ol6Y7SKs2dSa2ROuGbC1wE/DIiLgT+xbQpNiKCNpeA\nJG2UtFPSzqmpqab12hCpE75DwKGI2F7WH6AKozuTWiMnDV9EvAG8Lum8sulqYC/uTGoN1b299h3g\nHknzgVeAb1AF151JbdZqhS8idgOrT/Ardya1WfMdDkvj8Fkah8/SOHyWxuGzNA6fpXH4LI2q27J9\n2pn0FtUF6U8Bf+vbjk/so1ADDGcdn4mIs072pr6G7/2dSjtbvrE8xUehhlGvw9OupXH4LE1W+CaS\n9tvqo1ADjHAdKcd8ZuBp1xL1NXyS1kraL+mgpL592k3SXZKOStrTsq3vH/2UtFTSNkl7Jb0g6caM\nWiSdIulpSc+VOm4p25dL2l7+PveX5zd7JyL68gLmAC8D5wLzgeeAlX3a95VUj/7vadn2M2BTWd4E\n3NqHOhYDF5Xl04GXgJX9roWqzd5pZXkesB24FNgMrC/bfwV8s6d19DF8lwFPtqzfDNzcx/0vmxa+\n/cDillDs71ctLTU8AqzJrAUYA54FLqG6yDz3RH+vXrz6Oe2eA7zesn6obMuS+tFPScuAC6lGnb7X\nImmOpN1UH/zaQjUrTUbEsfKWnv99fMLBzB/97AVJpwEPAjdFxDsZtUTEexGxClgCXAyc3+t9TtfP\n8B0GlrasLynbstT66Ge3SZpHFbx7IuKhzFoAouo+sY1qmh2XdPxzPT3/+/QzfDuAFeWMaj6wnurj\nl1n6/tFPSaJqO7IvIm7LqkXSWZLGy/KpVMed+6hCeF2/6uj3AfY1VGd4LwM/6uN+7wWOAP+lOpbZ\nAJxJ1eDoAPAHYGEf6riCakp9HthdXtf0uxbgc8CuUsce4Mdl+7nA08BB4HfAx3tZh+9wWBqfcFga\nh8/SOHyWxuGzNA6fpXH4LI3DZ2kcPkvzf3SwfwHIHY9JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f122d837470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:53<07:35, 113.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_generator: 0.12397450953722;                  m: 0.2046774923801422;                  loss_discriminator:  0.21908731758594513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:25<00:00, 113.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_generator: 0.07378298044204712;                  m: 0.16960525512695312;                  loss_discriminator:  0.16225391626358032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k_t = train(5, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAAD8CAYAAABpe3YUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f122ced3898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "lr = lr / 2\n",
    "adjust_learning_rate(optimizerD,lr)\n",
    "adjust_learning_rate(optimizerG,lr)\n",
    "k_t = train(5, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t = train(100, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(100, k_t)\n",
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(100, k_t)\n",
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(100, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(200, k_t)\n",
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(200, k_t)\n",
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(200, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr / 2\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr)\n",
    "k_t = train(200, k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(netG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
